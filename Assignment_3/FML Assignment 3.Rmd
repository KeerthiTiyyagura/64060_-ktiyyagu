---
title: "Assignment 3"
author: "keerthi Tiyyagura"
date: "2023-10-15"
output:
  word_document: default
  pdf_document: default
  html_document: default
---
Summary:

The goal of this research was to determine from  initial reports and associated data in the accidents dataset whether an accident will involve an injury or not.

1.Initial Prediction: Let us start by creating a dummy variable named "INJURY," which takes the value "yes" if MAX_SEV_IR is 1 or 2, and "no" otherwise. This was done to determine the initial prediction if no further information is available. The prediction would be "yes" if there's an injury (MAX_SEV_IR = 1 or 2), and "no" if there's no injury (MAX_SEV_IR = 0).So for the prediction "YES" its giving 0.508 and 0.491 for prediction "NO".

2.1.Pivot Table Analysis: We looked at the response variable (INJURY) and the two predictors (WEATHER_R and TRAF_CON_R) for the dataset's first 24 records. To assess INJURY as a function of these two predictors, a pivot table was made. For six possible combinations of the predictors, the precise Bayes conditional probability of an injury were estimated.

2.2.Classification of 24 Accidents: The 24 accidents were classified using these probabilities with a cutoff of 0.5. The calculated probabilities were compared to the cutoff to determine if an injury was predicted or not.

2.3.Manual Bayes Probability Calculation: The naive Bayes conditional probability of an injury was calculated manually for certain values of the predictors (WEATHER_R = 1 and TRAF_CON_R = 1) and giving the value as "0".

2.4.Naive Bayes Classification: A naive Bayes classifier was run on the 24 records using the predictors WEATHER_R and TRAF_CON_R. The model output provided probabilities and classifications. This classification was compared to the exact Bayes classification to check for equivalence in results and ranking of observations.

3.1.Full Dataset Analysis: Training sets made up 60% of the dataset, and validation sets made up 40%. On the training set with the relevant predictors, a naive Bayes classifier was applied, and a confusion matrix was generated.

3.2.Overall Error Calculation: The overall error rate for the validation set was calculated using the confusion matrix. The overall error rate represents the accuracy of the predictive model on the validation data.The overall error rate is 0.4668721.

## Questions

The file accidentsFull.csv contains information on 42,183 actual automobile accidents in 2001 in the United States that involved one of three levels of injury: NO INJURY, INJURY, or FATALITY. For each accident, additional information is recorded, such as day of week, weather conditions, and road type. A firm might be interested in developing a system for quickly classifying the severity of an accident based on initial reports and associated data in the system (some of which rely on GPS-assisted reporting).

Our goal here is to predict whether an accident just reported will involve an injury (MAX_SEV_IR = 1 or 2) or will not (MAX_SEV_IR = 0). For this purpose, create a dummy variable called INJURY that takes the value “yes” if MAX_SEV_IR = 1 or 2, and otherwise “no.”

```{r}
library(e1071)
library(caret)
```
1. Using the information in this dataset, if an accident has just been reported and no further information is available, what should the prediction be? (INJURY = Yes or No?) Why?
```{r}
accidents <- read.csv("C:/Users/keert/Downloads/accidentsFull.csv")
accidents$INJURY = ifelse(accidents$MAX_SEV_IR>0,"yes","no")
table(accidents$INJURY)
```


```{r}
# Convert variables to factor
for (i in c(1:dim(accidents)[2])){
  accidents[,i] <- as.factor(accidents[,i])
}
head(accidents,n=24)
```

```{r}
prob_yes <- mean(accidents$INJURY=="yes")
prob_no <- mean(accidents$INJURY=="no")
prob_yes
prob_no
```

2. Select the first 24 records in the dataset and look only at the response (INJURY) and the two predictors WEATHER_R and TRAF_CON_R. Create a pivot table that examines INJURY as a function of the two predictors for these 24 records. Use all three variables in the pivot table as rows/columns.     

```{r}
accidents24 <- accidents[1:24,c("INJURY","WEATHER_R","TRAF_CON_R")]
#head(accidents24)
```

```{r}
dt1 <- ftable(accidents24)
dt2 <- ftable(accidents24[,-1]) # print table only for conditions
dt1
dt2
```
  *. Compute the exact Bayes conditional probabilities of an injury (INJURY = Yes) given the six possible combinations of the predictors.
```{r}
# Injury = yes
p1 = dt1[3,1] / dt2[1,1] # Injury, Weather=1 and Traf=0
p2 = dt1[4,1] / dt2[2,1] # Injury, Weather=2, Traf=0
p3 = dt1[3,2] / dt2[1,2] # Injury, W=1, T=1
p4 = dt1[4,2] / dt2[2,2] # I, W=2,T=1
p5 = dt1[3,3] / dt2[1,3] # I, W=1,T=2
p6 = dt1[4,3]/ dt2[2,3] #I,W=2,T=2

# Injury = no
n1 = dt1[1,1] / dt2[1,1] # Weather=1 and Traf=0
n2 = dt1[2,1] / dt2[2,1] # Weather=2, Traf=0
n3 = dt1[1,2] / dt2[1,2] # W=1, T=1
n4 = dt1[2,2] / dt2[2,2] # W=2,T=1
n5 = dt1[1,3] / dt2[1,3] # W=1,T=2
n6 = dt1[2,3] / dt2[2,3] # W=2,T=2
print(c(p1,p2,p3,p4,p5,p6))
print(c(n1,n2,n3,n4,n5,n6))
```
  *. Classify the 24 accidents using these probabilities and a cutoff of 0.5.
```{r}
prob.inj <- rep(0,24)

for (i in 1:24) {
  print(c(accidents24$WEATHER_R[i],accidents24$TRAF_CON_R[i]))
    if (accidents24$WEATHER_R[i] == "1") {
      if (accidents24$TRAF_CON_R[i]=="0"){
        prob.inj[i] = p1
      }
      else if (accidents24$TRAF_CON_R[i]=="1") {
        prob.inj[i] = p3
      }
      else if (accidents24$TRAF_CON_R[i]=="2") {
        prob.inj[i] = p5
      }
    }
    else {
      if (accidents24$TRAF_CON_R[i]=="0"){
        prob.inj[i] = p2
      }
      else if (accidents24$TRAF_CON_R[i]=="1") {
        prob.inj[i] = p4
      }
      else if (accidents24$TRAF_CON_R[i]=="2") {
        prob.inj[i] = p6
      }
    }
  }
  
```

```{r}
accidents24$prob.inj <- prob.inj
accidents24$prob.inj
accidents24$pred.prob <- ifelse(accidents24$prob.inj>0.5,"yes","no")
accidents24$pred.prob
```

*. Compute manually the naive Bayes conditional probability of an injury given WEATHER_R = 1 and TRAF_CON_R = 1.
```{r}
naiveBayesprobability <- function(Pr_W1_Y,Pr_T1_Y,Pr_Y,Pr_W1_N,Pr_T1_N,Pr_N){
  numerator <- Pr_W1_Y*Pr_T1_Y*Pr_Y
  denominator <- Pr_W1_Y*Pr_T1_Y*Pr_Y+Pr_W1_N*Pr_T1_N*Pr_N
  conditional_probability <- numerator/denominator
  return(conditional_probability)
}
Pr_W1_Y <- 0.7
Pr_T1_Y <- 0.8
Pr_Y <- 0.4
Pr_W1_N <- 0.3
Pr_T1_N <- 0.2
Pr_N <- 0.6
result <- naiveBayesprobability(Pr_W1_Y,Pr_T1_Y,Pr_Y,Pr_W1_N,Pr_T1_N,Pr_N)
result
pr_injury_yes_given_weather1_traf1 <- p3
pr_injury_yes_given_weather1_traf1
```
*. Run a naive Bayes classifier on the 24 records and two predictors. Check the model output to obtain probabilities and classifications for all 24 records. Compare this to the exact Bayes classification. Are the resulting classifications equivalent? Is the ranking (= ordering) of observations equivalent?
```{r}
nb <- naiveBayes(INJURY ~ TRAF_CON_R + WEATHER_R, 
                 data = accidents24)

nbt <- predict(nb, newdata = accidents24,type = "raw")
accidents24$nbpred.prob <- nbt[,2] # Transfer the "Yes" nb prediction
head(accidents24)
```
Let us use Caret
```{r}
nb2 <- train(INJURY ~ TRAF_CON_R + WEATHER_R, 
      data = accidents24, method = "nb")
predict(nb2, newdata = accidents24[,c("INJURY", "WEATHER_R", "TRAF_CON_R")])
predict(nb2, newdata = accidents24[,c("INJURY", "WEATHER_R", "TRAF_CON_R")],
                                    type = "raw")
nb2
```

3. Let us now return to the entire dataset. Partition the data into training (60%) and validation (40%). 
  *.Run a naive Bayes classifier on the complete training set with the relevant predictors (and INJURY as the response). Note that all predictors are categorical. Show the confusion matrix.
```{r}
set.seed(1)

train_df <- sample(row.names(accidents),0.6*dim(accidents)[1])
valid_df <- setdiff(row.names(accidents),train_df)

train.df <- accidents[train_df,]
valid.df <- accidents[valid_df,]

# Defining a variable to be used

vars <- c("INJURY", "HOUR_I_R", "ALIGN_I" ,"WRK_ZONE",  "WKDY_I_R",
          "INT_HWY",  "LGTCON_I_R", "PROFIL_I_R", "SPD_LIM", "SUR_COND",
          "TRAF_CON_R",   "TRAF_WAY",   "WEATHER_R")

naivepred <- naiveBayes(INJURY~.,data = train.df[,vars])
naivepred
```
*. What is the overall error of the validation set?
```{r}
confusion_Matrix =  confusionMatrix(valid.df$INJURY, predict(naivepred, valid.df[, vars]), positive = "yes")

print(confusion_Matrix)

# Calculated Overall Error
overall_error_rate = 1 - confusion_Matrix$overall["Accuracy"]

cat("Overall Error", overall_error_rate)
```



